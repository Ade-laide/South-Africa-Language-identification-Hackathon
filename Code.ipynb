{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9cd3b9",
   "metadata": {},
   "source": [
    "#                     South African Language Identification Hack 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17513ddf",
   "metadata": {},
   "source": [
    "## Description of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07daa6",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c11bf",
   "metadata": {},
   "source": [
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d07ef3",
   "metadata": {},
   "source": [
    "We start by `importing` relevant libraries and modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "063d4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "#Libraries for data cleaning and preprocessing\n",
    "#Libraries for data preparation and model building\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543993b",
   "metadata": {},
   "source": [
    "## 2. Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d524b",
   "metadata": {},
   "source": [
    "We frist start by loading in our dataset, both the `training` and `testing` dataset are loaded as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406c5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training and test data set\n",
    "df_train=pd.read_csv('train_set.csv')\n",
    "df_test=pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8ad86",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c818ae19",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) : After loading in our dataset, we first begin with the vital component which is the EDA, to better understand the dataset we are working with and to gain insight about the `features` and `labels` by performing `Univariate` or `Multivariate` , `Non-graphical` or `Graphical Analysis`\"\n",
    "\n",
    "We will take a quick look at the first few rows of the training and testing dataset to have an overview of our features and labels (using `pd.head()` method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b26c3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# five rows of the traing dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7c1d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# five rows of the test dataset\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d28380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 33000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "#check the shape of training dataframe\n",
    "df_train.shape\n",
    "print(\"The training dataset has {0} rows and {1} columns\".format(df_train.shape[0], df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b574d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       1\n",
       "3818    1\n",
       "3794    1\n",
       "3793    1\n",
       "3792    1\n",
       "       ..\n",
       "1893    1\n",
       "1892    1\n",
       "1891    1\n",
       "1890    1\n",
       "5682    1\n",
       "Name: index, Length: 5682, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for unique values\n",
    "df_test[\"index\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7f79e",
   "metadata": {},
   "source": [
    "Show the number of `languages` and the total number of `sentenses` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfd6b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for unique values\n",
    "df_train[\"lang_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95bc2fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#check the information of the dataframe\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff25efa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1    i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2    the province of kwazulu-natal department of tr...\n",
       "3    o netefatša gore o ba file dilo ka moka tše le...\n",
       "4    khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the stop words\n",
    "df_train['text'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65055be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the distribution of unique label values\n",
    "f, ax = plt.subplots(figsize=(8, 4))\n",
    "ax = sns.countplot(x=\"lang_id\", data=df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2dd84f",
   "metadata": {},
   "source": [
    "## 4 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c126462",
   "metadata": {},
   "source": [
    "In this Section we will be applying `feature engineering` to our dataset, we will try to enrich the dataset and if possible add some new features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce42d76",
   "metadata": {},
   "source": [
    "We will start by Classifying the `independent` and `dependent` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710e6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[\"text\"] #text is an independent variable of the train data\n",
    "y = df_train[\"lang_id\"] #lang_id is an dependent variable of the train data\n",
    "X_tt = df_test['text'] #text is an independent variable of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac8c49",
   "metadata": {},
   "source": [
    "We are now preocessing our data by \n",
    "`Cleaning` our dataset to remove symbols that will determine the quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b86cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatin a list for appending the preprocessed text\n",
    "df_list = []\n",
    "# iterating through all the text\n",
    "for text in X:\n",
    "       # removing the symbols and numbers\n",
    "        text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)\n",
    "        # converting the text to lower case\n",
    "        text = text.lower()\n",
    "        # appending to data_list\n",
    "        df_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43ef795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a list for appending the preprocessed text in the text data set\n",
    "df_list1 = []\n",
    "# iterating through all the text\n",
    "for text in X_tt:\n",
    "       # removing the symbols and numbers\n",
    "        text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)\n",
    "        text = re.sub(r'[[]]', ' ', text)\n",
    "        text = text.lower()\n",
    "        # appending to data_list\n",
    "        df_list1.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90052939",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "- We want Our model to take in numerical data Using `CountVectorizer` to convert our dataset from text to numerical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b37fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1630b016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 141958)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the shape\n",
    "X.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2886e",
   "metadata": {},
   "source": [
    "We use `transform` on the test dataset because we have used the scaled paramaters learned from the train data to scale the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f22ce1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 141958)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test data is transformed using transform()\n",
    "X_tt = cv.transform(X_tt)\n",
    "X_tt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83c0fd",
   "metadata": {},
   "source": [
    "Train Test Splitting Creating the training set, for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43083265",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b642530",
   "metadata": {},
   "source": [
    "### Model Training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5cc27",
   "metadata": {},
   "source": [
    "Here we train our model uisng different models from the training set and later predict the output for the test set using the `classification report`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0812b",
   "metadata": {},
   "source": [
    "### Naive_Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c3138f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9990909090909091\n",
      "Report is :               precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       587\n",
      "         eng       0.99      1.00      1.00       574\n",
      "         nbl       1.00      1.00      1.00       613\n",
      "         nso       1.00      1.00      1.00       570\n",
      "         sot       1.00      1.00      1.00       600\n",
      "         ssw       1.00      1.00      1.00       624\n",
      "         tsn       1.00      1.00      1.00       581\n",
      "         tso       1.00      1.00      1.00       597\n",
      "         ven       1.00      1.00      1.00       599\n",
      "         xho       1.00      1.00      1.00       621\n",
      "         zul       1.00      1.00      1.00       634\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "\n",
    "#fitting the Naive_Bayes model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#predicting the y labels\n",
    "y_pred1 = model.predict(x_test)\n",
    "\n",
    "#metrics reporting\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "report = classification_report(y_test,y_pred1)\n",
    "\n",
    "print(\"Accuracy is :\",acc)\n",
    "#print(\"Matrix is :\",cm)\n",
    "print(\"Report is :\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229bea26",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f67f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9940909090909091\n",
      "Report is :               precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       587\n",
      "         eng       1.00      1.00      1.00       574\n",
      "         nbl       0.99      0.98      0.98       613\n",
      "         nso       1.00      0.99      1.00       570\n",
      "         sot       1.00      0.99      1.00       600\n",
      "         ssw       0.99      1.00      1.00       624\n",
      "         tsn       0.99      1.00      1.00       581\n",
      "         tso       1.00      1.00      1.00       597\n",
      "         ven       1.00      1.00      1.00       599\n",
      "         xho       0.99      0.99      0.99       621\n",
      "         zul       0.97      0.98      0.98       634\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC( kernel='rbf')\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred4 = svc.predict(x_test)\n",
    "\n",
    "#metrics report\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "report = classification_report(y_test,y_pred4)\n",
    "\n",
    "print(\"Accuracy is :\",acc)\n",
    "print(\"Report is :\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e49376",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ee86b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9953030303030304\n",
      "Report is :               precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       587\n",
      "         eng       1.00      1.00      1.00       574\n",
      "         nbl       0.99      0.99      0.99       613\n",
      "         nso       1.00      1.00      1.00       570\n",
      "         sot       1.00      0.99      1.00       600\n",
      "         ssw       0.99      1.00      0.99       624\n",
      "         tsn       1.00      1.00      1.00       581\n",
      "         tso       1.00      1.00      1.00       597\n",
      "         ven       1.00      1.00      1.00       599\n",
      "         xho       1.00      0.99      0.99       621\n",
      "         zul       0.98      0.98      0.98       634\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)# Creating a logistics regression\n",
    "#fit the train data\n",
    "LRmodel.fit(x_train, y_train)\n",
    "#predict y labels\n",
    "y_pred2 = LRmodel.predict(x_test)\n",
    "\n",
    "#metrics report\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "report = classification_report(y_test,y_pred2)\n",
    "\n",
    "print(\"Accuracy is :\",acc)\n",
    "print(\"Report is :\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c20aa8",
   "metadata": {},
   "source": [
    " ## 5 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfb3c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c850e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_Bayes Metric results\n",
      "accuracy of the model is 0.9990909090909091\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of our Naive_Bayes Model.\n",
    "print('Naive_Bayes Metric results')\n",
    "print(\"accuracy of the model is {}\".format(model.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4128ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Metric results\n",
      "accuracy of the model is 0.9953030303030304\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of our Logistic Regression Model.\n",
    "print('LogisticRegression Metric results')\n",
    "print(\"accuracy of the model is {}\".format(LRmodel.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aca4efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Metric results\n",
      "accuracy of the model is 0.9940909090909091\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of our Support Vector Classifier.\n",
    "print('Support Vector Classifier Metric results')\n",
    "print(\"accuracy of the model is {}\".format(svc.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301398f",
   "metadata": {},
   "source": [
    "## Predictions with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0926264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pred= model.predict(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is used to save the predictions for kaggle.\n",
    "\n",
    "kaggle_bnb = df_test[['index']]\n",
    "kaggle_bnb['lang_id']= text_pred\n",
    "kaggle_bnb.to_csv(sample_submission.csv, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91643daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12816150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=pd.read_csv('sample_submission.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b4df3",
   "metadata": {},
   "source": [
    "# 6 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1447f19",
   "metadata": {},
   "source": [
    "We went through  feature engineering to improve the data, train a Machine Learning Model and arrive at a model with a good performance to better predict unseen data . We noticed that the Multinormal Naive Bayes has proven to be a better model in language, hence more accurate results were produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed56df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
